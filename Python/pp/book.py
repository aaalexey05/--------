import nltk
from nltk.tokenize import word_tokenize

text = "This is a example sentence for tokenization."

tokens = word_tokenize(text)

print(tokens)